## 高并发利器

  - 概述：缓存、限流、降级、熔断、隔离是高并发的5个利器
  - 参考：
    - https://www.codenong.com/cs109117406/

### 缓存

  - 概述：
    - 缓存分为本地缓存和分布式缓存两种：
      - 本地缓存：GuavaCache、Caffeine等
      - 分布式缓存：Redis、Memcached等
    - 缓存作用：
      - 提升软件响应速度
      - 解决数据库中查找速度慢的问题
    - 缓存三大特征：
      - 命中率：
        - 命中率 = 命中数 /（命中数+没有命中数）
        - 当某个请求能够通过访问缓存而得到响应时，称为缓存命中。缓存命中率越高，缓存的利用率也就越高
      - 最大空间：
        - 最大空间表示缓存中可以容纳最大的元素数量
        - 当缓存存放的数据超过最大空间时，就需要根据淘汰算法来淘汰部分数据存放新到达的数据
      - 淘汰算法：
        - FIFO（先进先出）：
          - 最先进入缓存的数据在缓存空间不够的情况下（超出最大元素限制）会优先被清除掉，以腾出新的空间接受新的数据
          - 比较的对象：缓存元素的创建时间
          - 业务场景：适用于保证高频数据有效性场景，优先保障最新数据可用
        - LFU(less frequently used)：最少使用
          - 仅根据元素的被使用次数判断，清除使用次数较少的元素释放空间
          - 比较的对象：元素的hitCount（命中次数）
          - 业务场景：适用于保证高频数据有效性场景
        - LRU(least recently used)：最近最少使用
          - 根据元素最后一次被使用的时间戳，清除最远使用时间戳的元素释放空间
          - 比较的对象：元素最近一次被get使用时间
          - 业务场景：适用于热点数据场景，优先保证热点数据的有效性
  - 本地缓存（进程内缓存）：
    - 概述：
      - 定义：应用和缓存都在同一个进程里面
      - 优点：获取缓存数据的时候是纯内存操作，没有额外的网络开销，速度非常快
      - 缺点：
        - 本地缓存与业务系统耦合在一起，应用之间无法直接共享缓存的内容
        - 本地缓存机器重启、或者宕机数据都会丢失
        - 需要每个应用节点单独的维护自己的缓存。每个节点都需要一份一样的缓存，对服务器内存造成一种浪费
    - 本地缓存更新方式：
      - 定时变量更新：
        - 在应用中起一个定时任务，每隔一段时间去加载变更的数据到缓存里面；数据变更之后可以修改数据库最后修改的时间，每次查询变更数据的时候都可以根据最后变更时间加上半小时大于当前时间的数据
      - 定时全量更新：
        - 每隔一段时间去加载加载全部的数据到缓存，这种方式对数据更新可能会有延迟。可能这台机器看到的是更新后的数据，那台机器看到的数据还是老的（因为机器发布时间可能不一样）
      - 广播订阅队列消息：
        - 如果对实时性有要求的话，使用广播订阅mq消息更新
        - 一旦有数据更新mq会把更新数据推送到每一台机器，实时性好，但是实现起来较为复杂
  - 分布式缓存：
    - 定义：与应用分离的缓存组件或服务，其最大的优点是自身就是一个独立的应用，与本地应用隔离，多个应用可直接共享缓存
  - 多级缓存：
    - 本地缓存+分布式缓存：本地缓存中只保存访问频率最高的部分热点数据，分布式缓存中保存其他的热点数据
  - 缓存存在的问题：
    - 缓存雪崩：
      - 定义：大量缓存同一时间段集体失效，或者缓存整体不能提供服务，导致大量的请求全部到达数据库，对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机
      - 解决方式：
        - 保证缓存的高可用，使用主从模式和集群模式来尽量保证缓存服务的高可用：
          - 使用Redis集群模式，即使个别redis节点下线，缓存还是可以用
          - 将热点数据均匀分布在不同的Redis库中也能避免全部失效的问题，单个服务对应单个Redis分片
        - 使用多级缓存（本地缓存 + 分布式缓存，推荐方式）：
          - 不同级别的缓存过期时间不同，即使某个级别缓存过期了，还有其他级别的缓存兜底
        - 缓存永不过期：
          - 优点：缓存永不过期，就不会发生缓存雪崩
          - 缺点：会浪费更多的存储空间
          - 应用场景：电商首页或特别热门的页面，因为访问量太大，不能使这部分缓存失效，因此牺牲一点存储空间
        - 使用随机过期时间（推荐方式）：
          - 为每一个key都合理的设计一个过期时间（在缓存时使用固定时间加上一个小的随机数），这样可以避免大量的热点key在同一时刻集体失效
    - 缓存穿透:
      - 定义：查询一个不存在的数据，则这些查询请求全部打到数据库或者接口，会导致数据库宕机或者服务大量超时
      - 解决方式：
        - nginx层：
          - 在网关层Nginx进行配置，对单个IP每秒访问次数超出阈值的IP都拉黑
        - controller层校验 + 缓存空值：
          - 在controller层增加校验，比如用户鉴权校验，参数做校验
          - 缓存空值：
            - 第1次查询，从缓存取不到，并且在数据库中也没有取到的数据，在缓存中将对应Key的Value置为null；
            - 第2-n次查询，后续相同ID的请求直接返回，从而避免相同ID的请求再次访问DB
        - 使用布隆过滤器：
          - 查询缓存之前先去布隆过滤器查询下这个数据是否存在，如果数据不存在，直接返回空
    - 缓存击穿：
      - 定义：某个热点数据失效时，大量针对这个数据的请求会穿透到数据源
      - 解决方式：
        - 缓存永不过期：同上
        - 异步重建缓存：
          - 需要定时去轮询这些key的过期时间，例如一个key的value设置的过期时间是30min，可以为这个key设置过期时间为20min。所以当这个key到20min的时候重新去构建这个key的缓存，同时也更新这个key的一个过期时间
        - 互斥锁：
          - 针对于同一个key，借助redis分布式锁来构建缓存，让只有一个请求可以去查询DB其他N个请求等待，等A查询到数据并且把缓存构建好之后，其他N个请求都只需要从缓存取数据
    - 缓存更新：
      - 四种缓存更新方式:
        - 先更新缓存，再更新数据库
        - 先更新数据库，再更新缓存
        - 先删除缓存，再更新数据库
        - 先更新数据库，再删除缓存（推荐）
      - 最经典的缓存+数据库读写的模式是Cache Aside Pattern:
        - 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应
        - 写的时候，先更新数据库，然后再删除缓存
      - 为什么写的时候，是删除缓存，而不是更新缓存？
        - 对于复杂的缓存场景，缓存不单单是数据库中直接取出来的值，而是数据库中取出来并适当计算的值
        - 更新缓存的代价有时候是很高的，所以使用懒加载，需要用到的时候才更新缓存
        - 避免频繁写而不是频繁读
    - 缓存数据不一致：
      - 定义：缓存数据不一致产生的原因一般是主动更新失败，例如更新DB后，更新Redis网络请求超时或者是异步更新失败
      - 解决方式：
        - 如果服务对耗时不是特别敏感，可以增加重试
        - 如果服务对耗时敏感，可以通过异步补偿任务来处理失败的更新，或者短期的数据不一致不会影响业务，那么只要下次更新时可以成功，能保证最终一致性就可以

### 限流

  - 定义：
    - 限流就是限制系统的输入和输出流量，达到保护系统的目的
    - 系统的吞吐量是可以被测算的，为了保证系统的稳定运行，一旦达到限制的阈值，就需要采取一些措施以完成限制流量的目的，比如：延迟处理，拒绝处理，或者部分拒绝处理等
  - 限流的四个原则：
    - 后端不做任何干涉，完全交给不确定的网络，先到达的请求先处理，后到达的请求后处理，达到阈值直接拒绝服务
    - 后端对服务分级，对于核心服务的请求就处理，对于非核心的请求不处理，又称服务的主动降级
    - 后端所有请求都处理，但是放到延迟队列中，一点一点的处理
    - 后端对用户分级，对于重要用户的请求优先处理，对于普通用户的请求普通处理
  - 限流的实现：
    - 计数器方法(达到阈值直接拒绝访问)：
      - 系统维护一个计数器，来一个请求就加1，请求处理完成就减1，当计数器大于指定的阈值，就拒绝新的请求
      - 通常应用在池化技术上面比如：数据库连接池、线程池等
    - 漏桶算法：
      - 流入速率即实际的用户请求速率或压力测试的速率；流出速率即服务端处理速率
      - 一般来说，流出速率是固定的。当然，特殊情况下，需要加快速度处理，也可以动态调整流出速率
    - 令牌桶：
      - 每个请求过来必须拿到桶里面拿到了令牌才允许请求，拿不到令牌的话直接拒绝
      - 令牌桶和漏桶不同点：
        - 令牌桶新增了一个匀速生产令牌的中间人以恒定的速度往桶里面放令牌；而漏桶流入速率不受控制，用户请求压力直接达到漏桶
    - 任何限流组件都要设置阈值，直接拒绝要设置阈值，漏桶和令牌桶要设置桶大小
      - 阈值设置过大的话，服务可能扛不住，阈值设置小了会把用户请求给误杀，资源没有得到最大利用

### 服务降级
      
  - 定义：当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行
  - 降级的类别：
    - 降级按照是否自动化可分为：自动开关降级和人工开关降级
      - 自动开关降级：根据系统负载、资源使用情况、SLA等指标进行降级
        - 超时降级：
          - 当访问的数据库/http服务/远程调用响应慢或者长时间响应慢，且该服务不是核心服务的话可以在超时后自动降级
        - 统计失败次数降级：
          - 调用的远程服务挂掉了（网络故障、DNS故障、http服务返回错误的状态码、rpc服务抛出异常），则可以直接降级
          - 降级后的处理方案：
            - 默认值（比如库存服务挂了，返回默认现货）
            - 兜底数据（比如广告挂了，返回提前准备好的一些静态页面）
        - 限流降级：
          - 秒杀或者抢购一些限购商品时，此时可能会因为访问量太大而导致系统崩溃，此时会使用限流来进行限制访问量，当达到限流阀值，后续请求会被降级
          - 降级后的处理方案：
            - 排队页面（将用户导流到排队页面等一会重试）
            - 无货（直接告知用户没货了）
            - 错误页（如活动太火爆了，稍后重试）
      - 人工开关降级：
        - 开关可以存放到配置文件、存放到数据库、存放到Redis/ZooKeeper，然后通过判断某个KEY的值来决定是否降级
    - 降级按照功能可分为：读服务降级、写服务降级
      - 读服务降级：
        - 采用的策略：
          - 暂时切换读（降级到读缓存、降级到走静态化），比如页面动态化降级为静态化，大促来临之际可以将其切换为静态化来减少对核心资源的占用，而且可以提升性能
          - 暂时屏蔽读（屏蔽读入口、屏蔽某个读服务）
      - 写服务降级：
        - 写服务在大多数场景下是不可降级的，不过可以通过一些迂回战术来解决问题。比如将同步操作转换为异步操作，或者限制写的量/比例
        - 比如扣减库存一般这样操作：
          - 扣减Redis库存
          - 正常同步扣减DB库存，性能扛不住时降级为写扣减DB库存消息到本机，然后本机通过异步进行DB库存扣减来实现最终一致性
    - 降级按照处于的系统层次可分为：多级降级
      - 降级是离用户越近越能对系统保护的好，因为业务的复杂性导致越到后端QPS/TPS越低
        - 页面JS降级开关：主要控制页面功能的降级，在页面中通过JS脚本部署功能降级开关，在适当时机开启/关闭开关
        - 接入层降级开关：主要控制请求入口的降级，请求进入后会首先进入接入层，在接入层可以配置功能降级开关，可以根据实际情况进行自动/人工降级
        - 应用层降级开关：主要控制业务的降级，在应用中配置相应的功能开关，根据实际业务情况进行自动/人工降级
  - 降级的功能点：主要从服务端链路考虑，即根据用户访问的服务调用链路来梳理哪里需要降级
    - 页面降级：在大促或者某些特殊情况下，某些页面占用了一些稀缺服务资源，在紧急情况下可以对其整个降级，以达到丢卒保帅
    - 页面片段降级：比如商品详情页中的商家部分因为数据错误了，此时需要对其进行降级
    - 服务功能降级：比如渲染商品详情页时需要调用一些不太重要的服务：相关分类、热销榜等，而这些服务在异常情况下直接不获取，即降级即可
    - 读降级：比如多级缓存模式，如果后端服务有问题，可以降级为只读缓存，这种方式适用于对读一致性要求不高的场景
    - 写降级：比如秒杀抢购，我们可以只进行Cache的更新，然后异步同步扣减库存到DB，保证最终一致性即可，此时可以将DB降级为Cache
  - 参考：
    - https://cloud.tencent.com/developer/article/1165813

### 服务熔断

  - 服务雪崩：
    - 定义：多个微服务之间调用的时候，比如A服务调用了B服务，B服务调用了C服务，然后C服务由于机器宕机或者网略故障， 然后就会导致B服务调用C服务的时候超时，然后A服务调用B服务也会超时，最终整个链路都不可用了，导致整个系统不可用就跟雪蹦一样
    - 服务雪崩产生的原因：
      - 突增流量：比如一大波爬虫，或者黑客攻击等
      - 程序bug：代码死循环，或者资源未释放等
      - 硬件原因：机器宕机、机房断电、光纤被挖断等
  - 熔断机制：
    - 定义：熔断机制是应对雪崩效应的一种微服务链路保护机制，当下游的服务因为某种原因突然变得不可用或响应过慢，上游服务为了保证自己整体服务的可用性，暂时不再继续调用目标服务，直接快速返回失败标志，快速释放资源。如果目标服务情况好转则恢复调用
    
          
