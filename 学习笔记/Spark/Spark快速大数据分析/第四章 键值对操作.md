# 键值对操作

  - 键值对 RDD 通常用来进行聚合计算。
  - 一般要先通过一些初始ETL（抽取、转化、装载）操作来将数据转化为键值对形式。
  
## 动机

  - 包含键值对类型的RDD称为Pair RDD。它们提供了并行操作各个键或跨节点重新进行数据分组的操作接口。
    - reduceByKey()：分别归约每个键对应的数据。
    - join()：把两个 RDD 中键相同的元素组合到一起，合并为一个RDD。
  
## 创建Pair RDD

  - 很多存储键值对的数据格式会在读取时直接返回由其键值对数据组成的Pair RDD。
  - 当需要把一个普通的 RDD 转 为 pair RDD 时，可以调用 map() 函数来实现，传递的函数需要返回键值对。
    ```
    val pairs = lines.map(x => (x.split(" ")(0), x))
    ```
  - Spark的Java API让用户使用scala.Tuple2类来创建二元组。通过 new Tuple2(elem1, elem2) 来创建一个新的二元组，并且可以通过 ._1() 和 ._2() 方法访问其中的元素。
  
## Pair RDD的转化操作

  - Pair RDD 可以使用所有标准RDD上的可用的转化操作。由于pair RDD中包含二元组，所以需要传递的函数应当操作二元组而不是独立的元素。
  - Pair RDD的转化操作:
    
    ![PairRDD转化操作1](./图片/PairRDD转化操作1.PNG)
    
    ![PairRDD转化操作2](./图片/PairRDD转化操作2.PNG)
    
### 聚合操作

  - reduceByKey()：
    - 与 reduce() 相当类似；它们都接收一个函数，并使用该函数对值进行合并。
    - reduceByKey() 会为数据集中的每个键进行并行的归约操作，每个归约操作会将键相同的值合并起来。
    - 例子：在 Scala 中使用 reduceByKey() 和 mapValues() 计算每个键对应的平均值。
      ```
      rdd.mapValues(x => (x, 1)).reduceByKey((x, y) => (x._1 + y._1, x._2 + y._2))
      ```
    - 例子：用 Scala 实现单词计数
      ```
      val input = sc.textFile("path")
      val words = input.flatMap(x => x.split(" "))
      val result = words.map(x => (x, 1)).reduceByKey((x, y) => x + y)
      ```
  - foldByKey()：
    - 与 fold() 相当类似；它们都使用一个与 RDD 和合并函数中的数据类型相同的零值作为初始值。
  - 调用reduceByKey()和foldByKey()会在为每个键计算全局的总结果之前先自动在每台机器上进行本地合并。用户不需要指定合并器。更泛化的combineByKey() 接口可以让你自定义合并的行为。
  - combineByKey()：
    - 如果这是一个新的元素，combineByKey()会使用一个叫作 createCombiner() 的函数来创建那个键对应的累加器的初始值。
    - 如果这是一个在处理当前分区之前已经遇到的键，它会使用 mergeValue() 方法将该键的累加器对应的当前值与这个新的值进行合并。
    - 由于每个分区都是独立处理的，因此对于同一个键可以有多个累加器。如果有两个或者更多的分区都有对应同一个键的累加器，就需要使用用户提供的 mergeCombiners() 方法将各个分区的结果进行合并。
    
### 并行度调优
  
  
