# Spark调优与调试

## Spark执行的组成部分：作业、任务和步骤

  - 特定的行动操作所生成的步骤的集合被称为一个作业。我们通过类似 count() 之类的方法触发行动操作，创建出由一个或多个步骤组成的作业。
  - 一个物理步骤会启动很多任务，每个任务都是在不同的数据分区上做同样的事情。
  - 任务内部的流程：
    - 从数据存储（如果该 RDD 是一个输入 RDD）或已有RDD（如果该步骤是基于已经缓存的数据）或数据混洗的输出中获取输入数据。
    - 执行必要的操作来计算出这些操作所代表的RDD。
    - 把输出写到一个数据混洗文件中，写入外部存储，或者是发回驱动器程序（如果最终RDD 调用的是类似 count() 这样的行动操作）。
  - Spark执行流程：
    - 用户代码定义RDD的有向无环图：RDD上的操作会创建出新的 RDD，并引用它们的父节点，这样就创建出了一个图。
    - 行动操作把有向无环图强制转译为执行计划：Spark调度器提交一个作业来计算所有必要的RDD。这个作业会包含一个或多个步骤，每个步骤其实也就是一波并行执行的计算任务。一个步骤对应有向无
环图中的一个或多个RDD。
    - 任务于集群中调度并执行：步骤是按顺序处理的，任务则独立地启动来计算出 RDD 的一部分。一旦作业的最后一个步骤结束，一个行动操作也就执行完毕了。
    
## 查找信息

  - Spark在应用执行时记录详细的进度信息和性能指标，存在于Spark的网页用户界面以及驱动器进程和执行器进程生成的日志文件中。
  
### Spark网页用户界面

  - 默认情况下，它在驱动器程序所在机器的 4040 端口上。对于 YARN 集群模式来说，应用的驱动器程序会运行在集群内部，通过YARN的资源管理器来访问用户界面。
  - Spark用户界面包括：
    - 作业页面：作业页面包含正在进行的或刚完成不久的Spark作业的详细执行情况。其中一个很重要的信息是正在运行的作业、步骤以及任务的进度情况。
    - 存储页面：已缓存的RDD的信息。
    - 执行器页面：应用中申请到的执行器实例，以及各执行器进程在数据处理和存储方面的一些指标。
    - 环境页面：应用所运行的环境中实际生效的配置项集合。
    
### 驱动器进程和执行器进程的日志

  - Spark日志文件的具体位置取决于以下部署模式：
    - 在Spark独立模式下，所有日志会在独立模式主节点的网页用户界面中直接显示。这些日志默认存储于各个工作节点的 Spark 目录下的 work/ 目录中。
    - 在Mesos模式下，日志存储在 Mesos 从节点的 work/ 目录中，可以通过 Mesos 主节点用户界面访问。
    - 在YARN模式下，最简单的收集日志的方法是使用YARN的日志收集工具（运行 yarn logs -applicationId <app ID>）来生成一个包含应用日志的报告。可以从资源管理器的用户界面点击进入节点
（Nodes）页面，然后浏览特定的节点，再从那里找到特定的容器。

## 关键性能考量

  - 并行度：
    - 在物理执行期间，RDD会被分为一系列的分区，每个分区都是整个数据的子集。输入RDD一般会根据其底层的存储系统选择并行度。Spark也会针对RDD直接自动推断出合适的并行度。
    - 并行度会从两方面影响程序的性能：
      - 首先，当并行度过低时，Spark集群会出现资源闲置的情况。而当并行度过高时，每个分区产生的间接开销累计起来就会更大。评判并行度是否过高的标准包括任务是否是几乎在瞬间
（毫秒级）完成的，或者是否观察到任务没有读写任何数据。
    - Spark提供了两种方法来对操作的并行度进行调优：
      - 第一种方法是在数据混洗操作时，使用参数的方式为混洗后的RDD指定并行度。
      - 第二种方法是对于任何已有的RDD，可以进行重新分区来获取更多或者更少的分区数。重新分区操作通过 repartition() 实现，该操作会把RDD随机打乱并分成设定的分区数目。如果你确定要减少 RDD 分区，可以使用
coalesce()操作。由于没有打乱数据，该操作比repartition()更为高效。
  - 序列化格式：
    - 当 Spark 需要通过网络传输数据，或是将数据溢写到磁盘上时，Spark需要把数据序列化为二进制格式。
    - 序列化会在数据进行混洗操作时发生，此时需要通过网络传输大量数据。默认情况下，Spark会使用Java内建的序列化库。Spark也支持使用第三方序列化库Kryo。
  - 内存管理：
    - 内存的用途：
      - RDD存储：当调用 RDD 的 persist() 或 cache() 方法时，这个 RDD 的分区会被存储到缓存区中。
      - 数据混洗与聚合的缓存区：这些缓存区用来存储聚合操作的中间结果，以及数据混洗操作中直接输出的部分缓存数据。
      - 用户代码：用户代码可以访问 JVM 堆空间中除分配给 RDD 存储和数据混洗存储以外的全部剩余空间。
      - 在默认情况下，Spark会使用60％的空间来存储RDD，20%存储数据混洗操作产生的数据，剩下的20%留给用户程序。用户可以自行调节这些选项来追求更好的性能表现。
  - 硬件供给：
    - 影响集群规模的主要参数包括分配给每个执行器节点的内存大小、每个执行器节点占用的核心数、执行器节点总数，以及用来存储临时数据的本地磁盘数量。
    
  
    
