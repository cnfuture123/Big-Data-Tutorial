# 在集群上运行Spark

## Spark运行时架构

  - 在分布式环境下，Spark集群采用的是主/从结构。在一个Spark集群中，有一个节点负责中央协调，调度各个分布式工作节点。这个中央协调节点被称为驱动器（Driver）节点，与之对应的工作节点被称为执行器（executor）节点。驱动器节点和所有的执行器节点一起被
称为一个 Spark应用（application）。
  - 分布式Spark应用中的组件：
    
    ![分布式Spark应用中的组件](./图片/分布式Spark应用中的组件.PNG)
    
### 驱动器节点

  - Spark驱动器是执行你的程序中的main()方法的进程。它执行用户编写的用来创建SparkContext、创建RDD，以及进行RDD的转化操作和行动操作的代码。驱动器程序一旦终止，Spark应用也就结束了。
  - 驱动器程序的两个职责：
    - 把用户程序转为任务：
      - Spark驱动器程序负责把用户程序转为多个物理执行的单元，这些单元也被称为任务task）。
      - Spark程序都遵循同样的结构：程序从输入数据创建一系列RDD，再使用转化操作派生出新的RDD，最后使用行动操作收集或存储结果RDD中的数据。
      - Spark程序其实是隐式地创建出了一个由操作组成的逻辑上的有向无环图（Directed Acyclic Graph，简称 DAG）。当驱动器程序运行时，它会把这个逻辑图转为物理执行计划。
      - 这样Spark就把逻辑计划转为一系列步骤（stage）。而每个步骤又由多个任务组成。这些任务会被打包并送到集群中。任务是Spark中最小的工作单元，用户程序通常要启动成百上千的独立任务。
    - 为执行器节点调度任务：
      - 有了物理执行计划之后，Spark 驱动器程序必须在各执行器进程间协调任务的调度。
      - 执行器进程启动后，会向驱动器进程注册自己。因此，驱动器进程始终对应用中所有的执行器节点有完整的记录。每个执行器节点代表一个能够处理任务和存储RDD数据的进程。
      - Spark驱动器程序会根据当前的执行器节点集合，尝试把所有任务基于数据所在位置分配给合适的执行器进程。当任务执行时，执行器进程会把缓存数据存储起来，而驱动器
进程同样会跟踪这些缓存数据的位置，并且利用这些位置信息来调度以后的任务，以尽量减少数据的网络传输。
  
### 执行器节点

  - Spark执行器节点是一种工作进程，负责在Spark作业中运行任务，任务间相互独立。
  - Spark应用启动时，执行器节点就被同时启动，并且始终伴随着整个Spark应用的生命周期而存在。
  - 执行器进程有两大作用：
    - 负责运行组成 Spark 应用的任务，并将结果返回给驱动器进程。
    - 通过自身的块管理器（Block Manager）为用户程序中要求缓存的RDD提供内存式存储。
  - 在本地模式下，Spark驱动器程序和各执行器程序在同一个 Java 进程中运行。
  
### 集群管理器

      
